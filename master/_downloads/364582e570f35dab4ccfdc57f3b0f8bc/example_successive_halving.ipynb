{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Successive Halving\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\n\nimport autosklearn.classification\n\n\ndef get_smac_object_callback(budget_type):\n    def get_smac_object(\n        scenario_dict,\n        seed,\n        ta,\n        ta_kwargs,\n        backend,\n        metalearning_configurations,\n    ):\n        from smac.facade.smac_ac_facade import SMAC4AC\n        from smac.intensification.successive_halving import SuccessiveHalving\n        from smac.runhistory.runhistory2epm import RunHistory2EPM4LogCost\n        from smac.scenario.scenario import Scenario\n\n        scenario_dict['input_psmac_dirs'] = backend.get_smac_output_glob(\n            smac_run_id=seed if not scenario_dict['shared-model'] else '*',\n        )\n        scenario = Scenario(scenario_dict)\n        if len(metalearning_configurations) > 0:\n            default_config = scenario.cs.get_default_configuration()\n            initial_configurations = [default_config] + metalearning_configurations\n        else:\n            initial_configurations = None\n        rh2EPM = RunHistory2EPM4LogCost\n\n        ta_kwargs['budget_type'] = budget_type\n\n        return SMAC4AC(\n            scenario=scenario,\n            rng=seed,\n            runhistory2epm=rh2EPM,\n            tae_runner=ta,\n            tae_runner_kwargs=ta_kwargs,\n            initial_configurations=initial_configurations,\n            run_id=seed,\n            intensifier=SuccessiveHalving,\n            intensifier_kwargs={\n                'initial_budget': 10.0,\n                'max_budget': 100,\n                'eta': 2,\n                'min_chall': 1},\n            )\n    return get_smac_object\n\n\ndef main():\n    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    X_train, X_test, y_train, y_test = \\\n        sklearn.model_selection.train_test_split(X, y, random_state=1, shuffle=True)\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=30,\n        per_run_time_limit=5,\n        tmp_folder='/tmp/autosklearn_sh_example_tmp',\n        output_folder='/tmp/autosklearn_sh_example_out',\n        disable_evaluator_output=False,\n        # 'holdout' with 'train_size'=0.67 is the default argument setting\n        # for AutoSklearnClassifier. It is explicitly specified in this example\n        # for demonstrational purpose.\n        resampling_strategy='holdout',\n        resampling_strategy_arguments={'train_size': 0.67},\n        include_estimators=['extra_trees', 'gradient_boosting', 'random_forest', 'sgd',\n                            'passive_aggressive'],\n        include_preprocessors=['no_preprocessing'],\n        get_smac_object_callback=get_smac_object_callback('iterations'),\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    # Print the final ensemble constructed by auto-sklearn.\n    print(automl.show_models())\n    predictions = automl.predict(X_test)\n    # Print statistics about the auto-sklearn run such as number of\n    # iterations, number of models failed with a time out.\n    print(automl.sprint_statistics())\n    print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n    # We can also use cross-validation with successive halving\n    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    X_train, X_test, y_train, y_test = \\\n        sklearn.model_selection.train_test_split(X, y, random_state=1, shuffle=True)\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=30,\n        per_run_time_limit=5,\n        tmp_folder='/tmp/autosklearn_sh_example_tmp',\n        output_folder='/tmp/autosklearn_sh_example_out',\n        disable_evaluator_output=False,\n        resampling_strategy='cv',\n        include_estimators=['extra_trees', 'gradient_boosting', 'random_forest', 'sgd',\n                            'passive_aggressive'],\n        include_preprocessors=['no_preprocessing'],\n        get_smac_object_callback=get_smac_object_callback('iterations'),\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    # Print the final ensemble constructed by auto-sklearn.\n    print(automl.show_models())\n    automl.refit(X_train, y_train)\n    predictions = automl.predict(X_test)\n    # Print statistics about the auto-sklearn run such as number of\n    # iterations, number of models failed with a time out.\n    print(automl.sprint_statistics())\n    print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n    # It is also possible to use an iterative fit cross-validation with successive halving\n    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    X_train, X_test, y_train, y_test = \\\n        sklearn.model_selection.train_test_split(X, y, random_state=1, shuffle=True)\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=30,\n        per_run_time_limit=5,\n        tmp_folder='/tmp/autosklearn_sh_example_tmp',\n        output_folder='/tmp/autosklearn_sh_example_out',\n        disable_evaluator_output=False,\n        resampling_strategy='cv-iterative-fit',\n        include_estimators=['extra_trees', 'gradient_boosting', 'random_forest', 'sgd',\n                            'passive_aggressive'],\n        include_preprocessors=['no_preprocessing'],\n        get_smac_object_callback=get_smac_object_callback('iterations'),\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    # Print the final ensemble constructed by auto-sklearn.\n    print(automl.show_models())\n    automl.refit(X_train, y_train)\n    predictions = automl.predict(X_test)\n    # Print statistics about the auto-sklearn run such as number of\n    # iterations, number of models failed with a time out.\n    print(automl.sprint_statistics())\n    print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n    # Next, we see the use of subsampling as a budget in Auto-sklearn\n    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    X_train, X_test, y_train, y_test = \\\n        sklearn.model_selection.train_test_split(X, y, random_state=1, shuffle=True)\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=30,\n        per_run_time_limit=5,\n        tmp_folder='/tmp/autosklearn_sh_example_tmp',\n        output_folder='/tmp/autosklearn_sh_example_out',\n        disable_evaluator_output=False,\n        # 'holdout' with 'train_size'=0.67 is the default argument setting\n        # for AutoSklearnClassifier. It is explicitly specified in this example\n        # for demonstrational purpose.\n        resampling_strategy='holdout',\n        resampling_strategy_arguments={'train_size': 0.67},\n        get_smac_object_callback=get_smac_object_callback('subsample'),\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    # Print the final ensemble constructed by auto-sklearn.\n    print(automl.show_models())\n    predictions = automl.predict(X_test)\n    # Print statistics about the auto-sklearn run such as number of\n    # iterations, number of models failed with a time out.\n    print(automl.sprint_statistics())\n    print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n    # Finally, there's a mixed budget type which uses iterations where possible and\n    # subsamples otherwise\n    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    X_train, X_test, y_train, y_test = \\\n        sklearn.model_selection.train_test_split(X, y, random_state=1, shuffle=True)\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=30,\n        per_run_time_limit=5,\n        tmp_folder='/tmp/autosklearn_sh_example_tmp',\n        output_folder='/tmp/autosklearn_sh_example_out',\n        disable_evaluator_output=False,\n        # 'holdout' with 'train_size'=0.67 is the default argument setting\n        # for AutoSklearnClassifier. It is explicitly specified in this example\n        # for demonstrational purpose.\n        resampling_strategy='holdout',\n        resampling_strategy_arguments={'train_size': 0.67},\n        include_estimators=['extra_trees', 'gradient_boosting', 'random_forest', 'sgd'],\n        get_smac_object_callback=get_smac_object_callback('mixed'),\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    # Print the final ensemble constructed by auto-sklearn.\n    print(automl.show_models())\n    predictions = automl.predict(X_test)\n    # Print statistics about the auto-sklearn run such as number of\n    # iterations, number of models failed with a time out.\n    print(automl.sprint_statistics())\n    print(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n\nif __name__ == '__main__':\n    main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}