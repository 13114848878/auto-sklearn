.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_example_crossvalidation.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr_examples_example_crossvalidation.py:


================
Cross-Validation
================

In *auto-sklearn* it is possible to use different resampling strategies
by specifying the arguments ``resampling_strategy`` and
``resampling_strategy_arguments``. The following example shows how to use
cross-validation and how to set the folds when instantiating
``AutoSklearnClassifier``.


.. code-block:: default


    import sklearn.model_selection
    import sklearn.datasets
    import sklearn.metrics

    import autosklearn.classification









Data Loading
============


.. code-block:: default


    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)
    X_train, X_test, y_train, y_test = \
        sklearn.model_selection.train_test_split(X, y, random_state=1)








Building  and fitting the classifier
====================================


.. code-block:: default


    automl = autosklearn.classification.AutoSklearnClassifier(
        time_left_for_this_task=120,
        per_run_time_limit=30,
        tmp_folder='/tmp/autosklearn_cv_example_tmp',
        output_folder='/tmp/autosklearn_cv_example_out',
        resampling_strategy='cv',
        resampling_strategy_arguments={'folds': 5},
    )

    # fit() changes the data in place, but refit needs the original data. We
    # therefore copy the data. In practice, one should reload the data
    automl.fit(X_train.copy(), y_train.copy(), dataset_name='breast_cancer')





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    AutoSklearnClassifier(delete_output_folder_after_terminate=True,
                          delete_tmp_folder_after_terminate=True,
                          disable_evaluator_output=False,
                          ensemble_memory_limit=1024, ensemble_nbest=50,
                          ensemble_size=50, exclude_estimators=None,
                          exclude_preprocessors=None, get_smac_object_callback=None,
                          include_estimators=None, include_preprocessors=None,
                          initial_configurations...
                          logging_config=None, max_models_on_disc=50,
                          metadata_directory=None, metric=None,
                          ml_memory_limit=3072, n_jobs=None,
                          output_folder='/tmp/autosklearn_cv_example_out',
                          per_run_time_limit=30, resampling_strategy='cv',
                          resampling_strategy_arguments={'folds': 5}, seed=1,
                          shared_mode=False, smac_scenario_args=None,
                          time_left_for_this_task=120,
                          tmp_folder='/tmp/autosklearn_cv_example_tmp')



Print Results before refit
==========================


.. code-block:: default

    print(automl.sprint_statistics())

    # One can use models trained during cross-validation directly to predict
    # for unseen data. For this, all k models trained during k-fold
    # cross-validation are considered as a single soft-voting ensemble inside
    # the ensemble constructed with ensemble selection.
    print('Before re-fit')
    predictions = automl.predict(X_test)
    print("Accuracy score", sklearn.metrics.accuracy_score(y_test, predictions))





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    auto-sklearn results:
      Dataset name: breast_cancer
      Metric: accuracy
      Best validation score: 0.964789
      Number of target algorithm runs: 19
      Number of successful target algorithm runs: 18
      Number of crashed target algorithm runs: 0
      Number of target algorithms that exceeded the time limit: 1
      Number of target algorithms that exceeded the memory limit: 0

    Before re-fit
    Accuracy score 0.958041958041958




Perform a refit
===============
During fit(), models are fit on individual cross-validation folds. To use
all available data, we call refit() which trains all models in the
final ensemble on the whole dataset.


.. code-block:: default

    automl.refit(X_train.copy(), y_train.copy())
    predictions = automl.predict(X_test)
    print("Accuracy score", sklearn.metrics.accuracy_score(y_test, predictions))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    Accuracy score 0.958041958041958





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 2 minutes  13.508 seconds)


.. _sphx_glr_download_examples_example_crossvalidation.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_crossvalidation.py <example_crossvalidation.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_crossvalidation.ipynb <example_crossvalidation.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
