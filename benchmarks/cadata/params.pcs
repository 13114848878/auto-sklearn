select_percentile_regression:percentile [10.0, 90.0] [50]
regressor {ridge_regression, gradient_boosting, random_forest, gaussian_process} [random_forest]
gradient_boosting:min_samples_split [2, 20] [2]i
rescaling:strategy {min/max, standard} [min/max]
gradient_boosting:loss {ls, lad} [ls]
random_forest:min_samples_split [2, 20] [2]i
gaussian_process:nugget [0.0001, 10.0] [0.1]l
pca:whiten {False, True} [False]
random_forest:max_features [0.5, 5.0] [1]
random_forest:min_samples_leaf [1, 20] [1]i
gradient_boosting:min_samples_leaf [1, 20] [1]i
kitchen_sinks:gamma [0.3, 2.0] [1.0]
select_percentile_regression:score_func {f_regression} [f_regression]
imputation:strategy {mean, median, most_frequent} [mean]
sparse_filtering:maxiter [50, 500] [100]i
gaussian_process:thetaL [1e-05, 0.001] [0.0001]l
gradient_boosting:subsample [0.01, 1.0] [1.0]
ridge_regression:alpha [0.0001, 10.0] [1.0]l
gradient_boosting:max_depth [1, 10] [3]i
preprocessor {None, sparse_filtering, select_percentile_regression, kitchen_sinks, pca} [None]
kitchen_sinks:n_components [50, 10000] [100]il
gaussian_process:thetaU [0.2, 10.0] [1.0]l
random_forest:max_depth {None} [None]
random_forest:criterion {mse} [mse]
random_forest:n_estimators {100} [100]
gradient_boosting:learning_rate [0.0001, 1.0] [0.1]l
pca:keep_variance [0.5, 1.0] [1.0]
gradient_boosting:n_estimators {100} [100]
random_forest:bootstrap {True, False} [True]
gradient_boosting:max_features [0.5, 5.0] [1]
sparse_filtering:N [50, 2000] [100]i

gaussian_process:thetaL | regressor in {gaussian_process}
random_forest:criterion | regressor in {random_forest}
gradient_boosting:subsample | regressor in {gradient_boosting}
gradient_boosting:learning_rate | regressor in {gradient_boosting}
random_forest:max_features | regressor in {random_forest}
ridge_regression:alpha | regressor in {ridge_regression}
random_forest:min_samples_leaf | regressor in {random_forest}
gradient_boosting:min_samples_leaf | regressor in {gradient_boosting}
gradient_boosting:min_samples_split | regressor in {gradient_boosting}
gradient_boosting:max_depth | regressor in {gradient_boosting}
gaussian_process:nugget | regressor in {gaussian_process}
gradient_boosting:n_estimators | regressor in {gradient_boosting}
gaussian_process:thetaU | regressor in {gaussian_process}
random_forest:bootstrap | regressor in {random_forest}
gradient_boosting:loss | regressor in {gradient_boosting}
random_forest:max_depth | regressor in {random_forest}
random_forest:min_samples_split | regressor in {random_forest}
gradient_boosting:max_features | regressor in {gradient_boosting}
random_forest:n_estimators | regressor in {random_forest}
select_percentile_regression:percentile | preprocessor in {select_percentile_regression}
pca:whiten | preprocessor in {pca}
pca:keep_variance | preprocessor in {pca}
kitchen_sinks:gamma | preprocessor in {kitchen_sinks}
sparse_filtering:N | preprocessor in {sparse_filtering}
kitchen_sinks:n_components | preprocessor in {kitchen_sinks}
select_percentile_regression:score_func | preprocessor in {select_percentile_regression}
sparse_filtering:maxiter | preprocessor in {sparse_filtering}

{regressor=random_forest, preprocessor=kitchen_sinks}
{regressor=random_forest, preprocessor=sparse_filtering}
{regressor=gradient_boosting, preprocessor=kitchen_sinks}
{regressor=gradient_boosting, preprocessor=sparse_filtering}
{regressor=gaussian_process, preprocessor=kitchen_sinks}
{regressor=gaussian_process, preprocessor=sparse_filtering}